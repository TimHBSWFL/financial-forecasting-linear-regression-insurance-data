{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d903e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "641162d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>month_index</th>\n",
       "      <th>product_Flood</th>\n",
       "      <th>product_Homeowners</th>\n",
       "      <th>product_Renters</th>\n",
       "      <th>region_Midwest</th>\n",
       "      <th>region_Northeast</th>\n",
       "      <th>region_South</th>\n",
       "      <th>region_West</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>21.52</td>\n",
       "      <td>2024-01-21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>12.76</td>\n",
       "      <td>2024-03-28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20.46</td>\n",
       "      <td>2024-11-04</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>91.27</td>\n",
       "      <td>2024-07-10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>197.09</td>\n",
       "      <td>2024-09-09</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   transaction_id  amount transaction_date  month_index  product_Flood  \\\n",
       "0               1   21.52       2024-01-21            1              0   \n",
       "1               2   12.76       2024-03-28            3              0   \n",
       "2               3   20.46       2024-11-04           11              0   \n",
       "3               4   91.27       2024-07-10            7              1   \n",
       "4               5  197.09       2024-09-09            9              1   \n",
       "\n",
       "   product_Homeowners  product_Renters  region_Midwest  region_Northeast  \\\n",
       "0                   0                1               0                 0   \n",
       "1                   0                1               0                 1   \n",
       "2                   0                1               0                 1   \n",
       "3                   0                0               0                 0   \n",
       "4                   0                0               0                 0   \n",
       "\n",
       "   region_South  region_West  \n",
       "0             0            1  \n",
       "1             0            0  \n",
       "2             0            0  \n",
       "3             1            0  \n",
       "4             1            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"C:/Users/tokud/Projects/Insurance Linear Regression/training.csv\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb1039d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 8) \n",
      "\n",
      "(20000, 8) \n",
      "\n",
      "(80000,) \n",
      "\n",
      "(20000,)\n"
     ]
    }
   ],
   "source": [
    "features = ['month_index', 'product_Flood', 'product_Homeowners', 'product_Renters',\n",
    "       'region_Midwest', 'region_Northeast', 'region_South', 'region_West']\n",
    "\n",
    "X = df[features]\n",
    "y = df['amount']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, \"\\n\")\n",
    "print(X_test.shape, \"\\n\")\n",
    "print(y_train.shape, \"\\n\")\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7629705",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = [\n",
    "    {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {\n",
    "            'copy_X': [True, False],\n",
    "            'fit_intercept': [True, False],\n",
    "            'positive': [True, False],\n",
    "            'tol': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'model': xgb.XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            tree_method='hist'\n",
    "            ),\n",
    "        'params': {\n",
    "            'max_depth': randint(3, 15),\n",
    "            'learning_rate': np.logspace(-3, 0, 100),\n",
    "            'n_estimators': randint(100, 1000),\n",
    "            'subsample': uniform(0.6, 0.4),\n",
    "            'colsample_bytree': uniform(0.6, 0.4)\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "    \n",
    "        'model': Lasso(),\n",
    "        'params': {\n",
    "            'alpha': np.logspace(-4, 2, 50),\n",
    "            'fit_intercept': [True, False],\n",
    "            'tol': [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'model': Ridge(),\n",
    "        'params': {\n",
    "            'alpha': np.logspace(-4, 3, 50),\n",
    "            'fit_intercept': [True, False],\n",
    "            'tol': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "            'solver': [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'model': DecisionTreeRegressor(),\n",
    "        'params': {\n",
    "            'max_depth': randint(3, 30),\n",
    "            'min_samples_split': randint(2, 20),\n",
    "            'min_samples_leaf': randint(1, 10),\n",
    "            'max_features': ['sqrt', 'log2', None, 0.3, 0.5, 0.8],\n",
    "            'max_leaf_nodes': [None] + list(range(10, 200, 20)),\n",
    "            'splitter': ['best', 'random']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'params': {\n",
    "            'max_depth': randint(3, 25),\n",
    "            'min_samples_leaf': randint(1, 10),\n",
    "            'min_samples_split': randint(2, 20),\n",
    "            'max_features': uniform(0.3, 0.7),\n",
    "            'n_estimators': randint(100, 500)\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f783165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Tuning LinearRegression with RandomizedSearchCV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tokud\\Projects\\venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:317: UserWarning: The total space of parameters 40 is smaller than n_iter=50. Running 40 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m Best score for LinearRegression: 0.9188\u001b[00m\n",
      "\u001b[96m Best parameters for LinearRegression: {'tol': 0.01, 'positive': True, 'fit_intercept': False, 'copy_X': True}\n",
      "\u001b[00m\n",
      "---Tuning XGBRegressor with RandomizedSearchCV\n",
      "\u001b[92m Best score for XGBRegressor: 0.9187\u001b[00m\n",
      "\u001b[96m Best parameters for XGBRegressor: {'colsample_bytree': np.float64(0.9268888800804863), 'learning_rate': np.float64(0.06135907273413173), 'max_depth': 3, 'n_estimators': 101, 'subsample': np.float64(0.9985014799031697)}\n",
      "\u001b[00m\n",
      "---Tuning Lasso with RandomizedSearchCV\n",
      "\u001b[92m Best score for Lasso: 0.9188\u001b[00m\n",
      "\u001b[96m Best parameters for Lasso: {'tol': 0.01, 'fit_intercept': True, 'alpha': np.float64(0.0007196856730011522)}\n",
      "\u001b[00m\n",
      "---Tuning Ridge with RandomizedSearchCV\n",
      "\u001b[92m Best score for Ridge: 0.9188\u001b[00m\n",
      "\u001b[96m Best parameters for Ridge: {'tol': 0.001, 'solver': 'svd', 'fit_intercept': True, 'alpha': np.float64(0.3727593720314938)}\n",
      "\u001b[00m\n",
      "---Tuning DecisionTreeRegressor with RandomizedSearchCV\n",
      "\u001b[92m Best score for DecisionTreeRegressor: 0.9187\u001b[00m\n",
      "\u001b[96m Best parameters for DecisionTreeRegressor: {'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 150, 'min_samples_leaf': 9, 'min_samples_split': 19, 'splitter': 'best'}\n",
      "\u001b[00m\n",
      "---Tuning RandomForestRegressor with RandomizedSearchCV\n",
      "\u001b[92m Best score for RandomForestRegressor: 0.9188\u001b[00m\n",
      "\u001b[96m Best parameters for RandomForestRegressor: {'max_depth': 3, 'max_features': np.float64(0.7440459412909546), 'min_samples_leaf': 2, 'min_samples_split': 13, 'n_estimators': 317}\n",
      "\u001b[00m\n",
      "Predicting with best LinearRegression\n",
      "\u001b[92m Mean Squared Error: 19.66996163555775\u001b[00m\n",
      "\u001b[96m R-Squared: 91.84768517552432\n",
      "\u001b[00m\n",
      "Predicting with best XGBRegressor\n",
      "\u001b[92m Mean Squared Error: 19.674425459845907\u001b[00m\n",
      "\u001b[96m R-Squared: 91.84398464669243\n",
      "\u001b[00m\n",
      "Predicting with best Lasso\n",
      "\u001b[92m Mean Squared Error: 19.669928926644786\u001b[00m\n",
      "\u001b[96m R-Squared: 91.84771228824972\n",
      "\u001b[00m\n",
      "Predicting with best Ridge\n",
      "\u001b[92m Mean Squared Error: 19.669974401740365\u001b[00m\n",
      "\u001b[96m R-Squared: 91.84767459350331\n",
      "\u001b[00m\n",
      "Predicting with best DecisionTreeRegressor\n",
      "\u001b[92m Mean Squared Error: 19.681613024640278\u001b[00m\n",
      "\u001b[96m R-Squared: 91.8380243611467\n",
      "\u001b[00m\n",
      "Predicting with best RandomForestRegressor\n",
      "\u001b[92m Mean Squared Error: 19.674906817397996\u001b[00m\n",
      "\u001b[96m R-Squared: 91.84358554913099\n",
      "\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "def prGreen(s): print(\"\\033[92m {}\\033[00m\".format(s))\n",
    "def prCyan(s): print(\"\\033[96m {}\\033[00m\".format(s))\n",
    "\n",
    "best_estimators = {}\n",
    "\n",
    "for model_type in model_dict:\n",
    "    model_name = type(model_type['model']).__name__\n",
    "    print(f\"---Tuning {model_name} with RandomizedSearchCV\")\n",
    "    \n",
    "    randomized_search = RandomizedSearchCV(\n",
    "        estimator = model_type['model'],\n",
    "        param_distributions = model_type['params'],\n",
    "        cv=5,\n",
    "        n_iter=50,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    randomized_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_estimators[model_name] = {\n",
    "        'best_estimator': randomized_search.best_estimator_,\n",
    "        'best_score': randomized_search.best_score_,\n",
    "        'best_params': randomized_search.best_params_\n",
    "    }\n",
    "    \n",
    "    prGreen(f\"Best score for {model_name}: {randomized_search.best_score_:.4f}\")\n",
    "    prCyan(f\"Best parameters for {model_name}: {randomized_search.best_params_}\\n\")\n",
    "    \n",
    "    \n",
    "for name, info in best_estimators.items():\n",
    "    print(f\"Predicting with best {name}\")\n",
    "    y_pred = info['best_estimator'].predict(X_test)\n",
    "    mse_new = mean_squared_error(y_test, y_pred)\n",
    "    r2_new = r2_score(y_test, y_pred)\n",
    "    \n",
    "    prGreen(f\"Mean Squared Error: {math.sqrt(mse_new)}\")\n",
    "    prCyan(f\"R-Squared: {(r2_new)*100}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75c861ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression: {'best_estimator': LinearRegression(fit_intercept=False, positive=True, tol=0.01), 'best_score': np.float64(0.9188155224594288), 'best_params': {'tol': 0.01, 'positive': True, 'fit_intercept': False, 'copy_X': True}}\n",
      "XGBRegressor: {'best_estimator': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=np.float64(0.9268888800804863), device=None,\n",
      "             early_stopping_rounds=None, enable_categorical=False,\n",
      "             eval_metric=None, feature_types=None, feature_weights=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None,\n",
      "             learning_rate=np.float64(0.06135907273413173), max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=101, n_jobs=None,\n",
      "             num_parallel_tree=None, ...), 'best_score': np.float64(0.9186802124919599), 'best_params': {'colsample_bytree': np.float64(0.9268888800804863), 'learning_rate': np.float64(0.06135907273413173), 'max_depth': 3, 'n_estimators': 101, 'subsample': np.float64(0.9985014799031697)}}\n",
      "Lasso: {'best_estimator': Lasso(alpha=np.float64(0.0007196856730011522), tol=0.01), 'best_score': np.float64(0.9188153427671315), 'best_params': {'tol': 0.01, 'fit_intercept': True, 'alpha': np.float64(0.0007196856730011522)}}\n",
      "Ridge: {'best_estimator': Ridge(alpha=np.float64(0.3727593720314938), solver='svd', tol=0.001), 'best_score': np.float64(0.9188152444617289), 'best_params': {'tol': 0.001, 'solver': 'svd', 'fit_intercept': True, 'alpha': np.float64(0.3727593720314938)}}\n",
      "DecisionTreeRegressor: {'best_estimator': DecisionTreeRegressor(max_depth=3, max_leaf_nodes=150, min_samples_leaf=9,\n",
      "                      min_samples_split=19), 'best_score': np.float64(0.9186953133139006), 'best_params': {'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 150, 'min_samples_leaf': 9, 'min_samples_split': 19, 'splitter': 'best'}}\n",
      "RandomForestRegressor: {'best_estimator': RandomForestRegressor(max_depth=3, max_features=np.float64(0.7440459412909546),\n",
      "                      min_samples_leaf=2, min_samples_split=13,\n",
      "                      n_estimators=317), 'best_score': np.float64(0.9187778409554056), 'best_params': {'max_depth': 3, 'max_features': np.float64(0.7440459412909546), 'min_samples_leaf': 2, 'min_samples_split': 13, 'n_estimators': 317}}\n"
     ]
    }
   ],
   "source": [
    "for key, value in best_estimators.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d4a98f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = [\n",
    "    {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {\n",
    "            'copy_X': [True],\n",
    "            'fit_intercept': [True, False],\n",
    "            'positive': [True],\n",
    "            'tol': [1e-2]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'model': xgb.XGBRegressor(\n",
    "            objective='reg:squarederror',\n",
    "            tree_method='hist'\n",
    "            ),\n",
    "        'params': {\n",
    "            'max_depth': [3, 4],\n",
    "            'learning_rate': [0.05, 0.06],\n",
    "            'n_estimators': [75, 100, 125],\n",
    "            'subsample': [0.98, 0.99],\n",
    "            'colsample_bytree': [0.92, 0.95]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "    \n",
    "        'model': Lasso(),\n",
    "        'params': {\n",
    "            'alpha': [0.0007, 0.001],\n",
    "            'fit_intercept': [True],\n",
    "            'tol': [1e-2, 1e-3]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'model': Ridge(),\n",
    "        'params': {\n",
    "            'alpha': [0.37, 0.5],\n",
    "            'fit_intercept': [True],\n",
    "            'tol': [1e-3, 1e-4],\n",
    "            'solver': [\"svd\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'model': DecisionTreeRegressor(),\n",
    "        'params': {\n",
    "            'max_depth': [3, 4],\n",
    "            'min_samples_split': [19, 20],\n",
    "            'min_samples_leaf': [8, 9, 10],\n",
    "            'max_features': [None],\n",
    "            'max_leaf_nodes': [140, 150, 160],\n",
    "            'splitter': ['best']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'model': RandomForestRegressor(),\n",
    "        'params': {\n",
    "            'max_depth': [3, 4],\n",
    "            'min_samples_leaf': [2, 3],\n",
    "            'min_samples_split': [13, 14],\n",
    "            'max_features': [0.74, 0.75, 0.76],\n",
    "            'n_estimators': [317, 325]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87182f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Tuning LinearRegression with GridSearchCV\n",
      "\u001b[92m Best score for LinearRegression: 0.9188\u001b[00m\n",
      "\u001b[96m Best parameters for LinearRegression: {'copy_X': True, 'fit_intercept': False, 'positive': True, 'tol': 0.01}\n",
      "\u001b[00m\n",
      "---Tuning XGBRegressor with GridSearchCV\n",
      "\u001b[92m Best score for XGBRegressor: 0.9187\u001b[00m\n",
      "\u001b[96m Best parameters for XGBRegressor: {'colsample_bytree': 0.92, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 125, 'subsample': 0.99}\n",
      "\u001b[00m\n",
      "---Tuning Lasso with GridSearchCV\n",
      "\u001b[92m Best score for Lasso: 0.9188\u001b[00m\n",
      "\u001b[96m Best parameters for Lasso: {'alpha': 0.001, 'fit_intercept': True, 'tol': 0.01}\n",
      "\u001b[00m\n",
      "---Tuning Ridge with GridSearchCV\n",
      "\u001b[92m Best score for Ridge: 0.9188\u001b[00m\n",
      "\u001b[96m Best parameters for Ridge: {'alpha': 0.37, 'fit_intercept': True, 'solver': 'svd', 'tol': 0.001}\n",
      "\u001b[00m\n",
      "---Tuning DecisionTreeRegressor with GridSearchCV\n",
      "\u001b[92m Best score for DecisionTreeRegressor: 0.9187\u001b[00m\n",
      "\u001b[96m Best parameters for DecisionTreeRegressor: {'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 140, 'min_samples_leaf': 8, 'min_samples_split': 19, 'splitter': 'best'}\n",
      "\u001b[00m\n",
      "---Tuning RandomForestRegressor with GridSearchCV\n",
      "\u001b[92m Best score for RandomForestRegressor: 0.9188\u001b[00m\n",
      "\u001b[96m Best parameters for RandomForestRegressor: {'max_depth': 3, 'max_features': 0.74, 'min_samples_leaf': 3, 'min_samples_split': 13, 'n_estimators': 325}\n",
      "\u001b[00m\n",
      "Predicting with best LinearRegression\n",
      "\u001b[92m Mean Squared Error: 19.66996163555775\u001b[00m\n",
      "\u001b[96m R-Squared: 91.84768517552432\n",
      "\u001b[00m\n",
      "Predicting with best XGBRegressor\n",
      "\u001b[92m Mean Squared Error: 19.6789154754779\u001b[00m\n",
      "\u001b[96m R-Squared: 91.84026155803497\n",
      "\u001b[00m\n",
      "Predicting with best Lasso\n",
      "\u001b[92m Mean Squared Error: 19.66991924019351\u001b[00m\n",
      "\u001b[96m R-Squared: 91.8477203174316\n",
      "\u001b[00m\n",
      "Predicting with best Ridge\n",
      "\u001b[92m Mean Squared Error: 19.669974306928406\u001b[00m\n",
      "\u001b[96m R-Squared: 91.84767467209396\n",
      "\u001b[00m\n",
      "Predicting with best DecisionTreeRegressor\n",
      "\u001b[92m Mean Squared Error: 19.681613024640278\u001b[00m\n",
      "\u001b[96m R-Squared: 91.8380243611467\n",
      "\u001b[00m\n",
      "Predicting with best RandomForestRegressor\n",
      "\u001b[92m Mean Squared Error: 19.68067206767674\u001b[00m\n",
      "\u001b[96m R-Squared: 91.83880477322126\n",
      "\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "best_estimators_grid = {}\n",
    "\n",
    "for model_type in model_dict:\n",
    "    model_name = type(model_type['model']).__name__\n",
    "    print(f\"---Tuning {model_name} with GridSearchCV\")\n",
    "    \n",
    "    grid_search = GridSearchCV(\n",
    "        estimator = model_type['model'],\n",
    "        param_grid = model_type['params'],\n",
    "        cv=5,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_estimators_grid[model_name] = {\n",
    "        'best_estimator': grid_search.best_estimator_,\n",
    "        'best_score': grid_search.best_score_,\n",
    "        'best_params': grid_search.best_params_\n",
    "    }\n",
    "    \n",
    "    prGreen(f\"Best score for {model_name}: {grid_search.best_score_:.4f}\")\n",
    "    prCyan(f\"Best parameters for {model_name}: {grid_search.best_params_}\\n\")\n",
    "    \n",
    "    \n",
    "for name, info in best_estimators_grid.items():\n",
    "    print(f\"Predicting with best {name}\")\n",
    "    y_pred = info['best_estimator'].predict(X_test)\n",
    "    mse_new = mean_squared_error(y_test, y_pred)\n",
    "    r2_new = r2_score(y_test, y_pred)\n",
    "    \n",
    "    prGreen(f\"Mean Squared Error: {math.sqrt(mse_new)}\")\n",
    "    prCyan(f\"R-Squared: {(r2_new)*100}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "192b1319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression {'best_estimator': LinearRegression(fit_intercept=False, positive=True, tol=0.01), 'best_score': np.float64(0.9188155224594288), 'best_params': {'copy_X': True, 'fit_intercept': False, 'positive': True, 'tol': 0.01}}\n",
      "XGBRegressor {'best_estimator': XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=0.92, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             feature_weights=None, gamma=None, grow_policy=None,\n",
      "             importance_type=None, interaction_constraints=None,\n",
      "             learning_rate=0.05, max_bin=None, max_cat_threshold=None,\n",
      "             max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
      "             max_leaves=None, min_child_weight=None, missing=nan,\n",
      "             monotone_constraints=None, multi_strategy=None, n_estimators=125,\n",
      "             n_jobs=None, num_parallel_tree=None, ...), 'best_score': np.float64(0.9186857003471294), 'best_params': {'colsample_bytree': 0.92, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 125, 'subsample': 0.99}}\n",
      "Lasso {'best_estimator': Lasso(alpha=0.001, tol=0.01), 'best_score': np.float64(0.9188153813238257), 'best_params': {'alpha': 0.001, 'fit_intercept': True, 'tol': 0.01}}\n",
      "Ridge {'best_estimator': Ridge(alpha=0.37, solver='svd', tol=0.001), 'best_score': np.float64(0.9188152444608603), 'best_params': {'alpha': 0.37, 'fit_intercept': True, 'solver': 'svd', 'tol': 0.001}}\n",
      "DecisionTreeRegressor {'best_estimator': DecisionTreeRegressor(max_depth=3, max_leaf_nodes=140, min_samples_leaf=8,\n",
      "                      min_samples_split=19), 'best_score': np.float64(0.9186953133139006), 'best_params': {'max_depth': 3, 'max_features': None, 'max_leaf_nodes': 140, 'min_samples_leaf': 8, 'min_samples_split': 19, 'splitter': 'best'}}\n",
      "RandomForestRegressor {'best_estimator': RandomForestRegressor(max_depth=3, max_features=0.74, min_samples_leaf=3,\n",
      "                      min_samples_split=13, n_estimators=325), 'best_score': np.float64(0.9187743329328562), 'best_params': {'max_depth': 3, 'max_features': 0.74, 'min_samples_leaf': 3, 'min_samples_split': 13, 'n_estimators': 325}}\n"
     ]
    }
   ],
   "source": [
    "for key, value in best_estimators_grid.items():\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4204ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = best_estimators_grid['Lasso']['best_estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "927eb965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/tokud/Projects/Insurance Linear Regression/best_model.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "directory = \"C:/Users/tokud/Projects/Insurance Linear Regression/best_model.pkl\"\n",
    "\n",
    "joblib.dump(best_model, directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
